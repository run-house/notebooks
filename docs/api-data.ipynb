{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8hjfzpOtNWu6"
   },
   "source": [
    "# Data: Folders, Tables, & Blobs\n",
    "\n",
    "Runhouse has several abstractions to provide a simple interface for storing, recalling, and moving data between the user’s laptop, remote compute, cloud storage, and specialized storage (e.g. data warehouses). \n",
    "\n",
    "The Folder, Table, and Blob APIs provide least-common-denominator APIs across providers, allowing users to easily specify the actions they want to take on the data without needed to dig into provider-specific APIs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4LZrV9xLyvM7"
   },
   "source": [
    "## Install Runhouse and Setup Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbOzhZrRyu1f"
   },
   "outputs": [],
   "source": [
    "!pip install runhouse[aws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4dBSfwHyyDu",
    "outputId": "803e4bbf-13e8-4c43-eabf-9e8ec9e519ae"
   },
   "outputs": [],
   "source": [
    "import runhouse as rh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "syFeJZsBy0Dg"
   },
   "source": [
    "Optionally, login to Runhouse to sync credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0CdXUbCyyZB"
   },
   "outputs": [],
   "source": [
    "!runhouse login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ij5fCxkZ8213"
   },
   "source": [
    "We also construct a Runhouse cluster object that we will use throughout the tutorial. We won't go in depth about clusters in this tutorial, but you can refer to Getting Started for setup instructions, or the Compute API tutorial for a more in-depth walkthrough of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJz_ouO58zob"
   },
   "outputs": [],
   "source": [
    "cluster = rh.ondemand_cluster(\n",
    "              name=\"cpu-cluster\",\n",
    "              instance_type=\"CPU:8\",\n",
    "              provider=\"cheapest\",       # \"AWS\", \"GCP\", \"Azure\", \"Lambda\", or \"cheapest\" (default)\n",
    "              autostop_mins=60,          # Optional, defaults to default_autostop_mins; -1 suspends autostop\n",
    "          )\n",
    "cluster.up()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IYyhMRnUyjKe"
   },
   "source": [
    "## Folders\n",
    "\n",
    "The Runhouse Folder API allows for creating references to folders, and syncing them between local, remote clusters, or file storage (S3, GS, Azure)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "M4mGLaYY9g14"
   },
   "source": [
    "Let's construct a sample dummy folder locally, that we'll use to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "91Qnj2g_9f1X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "folder_name = \"sample_folder\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "for i in range(5):\n",
    "  with open(f'{folder_name}/{i}.txt', 'w') as f:\n",
    "      f.write('i')\n",
    "\n",
    "local_path = f\"{os.getcwd()}/{folder_name}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FcOrBx3O8trk"
   },
   "source": [
    "To create a folder object, use the `rh.folder()` factory function, and use `.to()` to send the folder to a remote cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_nRqA7xHzBPF",
    "outputId": "8dcb3c6f-a00d-41e5-99e6-a21e093861dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 19:45:52.597164 | Copying folder from file:///Users/caroline/Documents/runhouse/runhouse/docs/notebooks/basics/sample_folder to: cpu-cluster, with path: sample_folder\n",
      "INFO | 2023-08-29 19:45:54.633598 | Running command on cpu-cluster: ls sample_folder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.txt\n",
      "1.txt\n",
      "2.txt\n",
      "3.txt\n",
      "4.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, '0.txt\\n1.txt\\n2.txt\\n3.txt\\n4.txt\\n', '')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_folder = rh.folder(path=f\"{os.getcwd()}/{folder_name}\")\n",
    "cluster_folder = local_folder.to(system=cluster, path=folder_name)\n",
    "\n",
    "cluster.run([f\"ls {folder_name}\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SeRZ-PD9DC5h"
   },
   "source": [
    "You can also send the folder to file storage, such as S3, GS, and Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O78jStem-f8T",
    "outputId": "9420142b-b911-456e-b1b2-163ac742882e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 19:47:47.618511 | Copying folder from file:///Users/caroline/Documents/runhouse/runhouse/docs/notebooks/basics/sample_folder to: s3, with path: /runhouse-folder/a6f195296945409da432b2981f984ae7\n",
      "INFO | 2023-08-29 19:47:47.721743 | Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO | 2023-08-29 19:47:48.796181 | Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.txt', '1.txt', '2.txt', '3.txt', '4.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_folder = local_folder.to(system=\"s3\")\n",
    "s3_folder.ls(full_paths=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-V1lAbB2FKZt"
   },
   "source": [
    "Similarly, you can send folders from a cluster to file storage, cluster to cluster, or file storage to file storage. These are all done without bouncing the folder off local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWRVktaeFI2z"
   },
   "outputs": [],
   "source": [
    "cluster_folder.to(system=another_cluster)  # cluster to cluster\n",
    "cluster_folder.to(system=\"s3\")             # cluster to fs\n",
    "s3_folder.to(system=cluster)               # fs to cluster\n",
    "s3_folder.to(system=\"gs\")                  # fs to fs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3znmdMxXymU5"
   },
   "source": [
    "## Tables\n",
    "\n",
    "The Runhouse Table API allows for abstracting tabular data storage, and supports interfaces for HuggingFace, Dask, Pandas, Rapids, and Ray tables (more in progress!).\n",
    "\n",
    "These can be synced and written down to local, remote clusters, or file storage (S3, GS, Azure).\n",
    "\n",
    "Let's step through an example using a Pandas table we upload to our s3 bucket using Runhouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlfZIXCeMnjz",
    "outputId": "f02f8ee9-50dc-4785-f0f7-29f650093f35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 19:55:29.834000 | Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "        {\"id\": [1, 2, 3, 4, 5, 6], \"grade\": [\"a\", \"b\", \"b\", \"a\", \"a\", \"e\"]}\n",
    "    )\n",
    "\n",
    "table_name = \"sample_table\"\n",
    "path = \"/runhouse-table/sample_table\"\n",
    "rh_table = rh.table(\n",
    "    data=df, name=table_name, path=path, system=\"s3\", mkdir=True\n",
    ").write().save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id grade\n",
       "0   1     a\n",
       "1   2     b\n",
       "2   3     b\n",
       "3   4     a\n",
       "4   5     a\n",
       "5   6     e"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh_table.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KxhQqhf-PLh0"
   },
   "source": [
    "To sync over and save the table to a remote cluster, or to local (\"here\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uywEtkPlPI4I",
    "outputId": "8168bd68-129e-46f8-a517-662324207e48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 19:59:39.456856 | Copying folder from s3://runhouse-table/sample_table to: cpu-cluster, with path: ~/.cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2\n",
      "INFO | 2023-08-29 19:59:39.458405 | Running command on cpu-cluster: aws --version >/dev/null 2>&1 || pip3 install awscli && aws s3 sync --no-follow-symlinks s3://runhouse-table/sample_table ~/.cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://runhouse-table/sample_table/d68a64f755014c049b6e97b120db5d0f.parquet to .cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2/d68a64f755014c049b6e97b120db5d0f.parquet\n",
      "download: s3://runhouse-table/sample_table/ebf7bbc1b22e4172b162b723b4b234f2.parquet to .cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2/ebf7bbc1b22e4172b162b723b4b234f2.parquet\n",
      "download: s3://runhouse-table/sample_table/53d00aa5fa2148dd9f4d9836f7b6a9be.parquet to .cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2/53d00aa5fa2148dd9f4d9836f7b6a9be.parquet\n",
      "download: s3://runhouse-table/sample_table/2d0aed0ba49d42509ae9124368a74323.parquet to .cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2/2d0aed0ba49d42509ae9124368a74323.parquet\n",
      "download: s3://runhouse-table/sample_table/ea3841db70874ee7aade6ff1299325c5.parquet to .cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2/ea3841db70874ee7aade6ff1299325c5.parquet\n",
      "download: s3://runhouse-table/sample_table/e7a7dce218054b6aa2b0853c12afe952.parquet to .cache/runhouse/82d19ef56425409fb92e5d4dfcd389e2/e7a7dce218054b6aa2b0853c12afe952.parquet\n"
     ]
    }
   ],
   "source": [
    "cluster_table = rh_table.to(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 19:59:49.336813 | Copying folder from s3://runhouse-table/sample_table to: file, with path: /Users/caroline/Documents/runhouse/runhouse/docs/notebooks/basics/sample_table\n"
     ]
    }
   ],
   "source": [
    "local_table = rh_table.to('here')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P68Hrzv_RhH0"
   },
   "source": [
    "To stream batches of the table, we reload the table object, but with an iterable `.data` field, using the `rh.table` constructor and passing in the name.\n",
    "\n",
    "Note that you can't directly do this with the original table object, as its `.data` field is the original `data` passed in, and not necessarily in an iterable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "v9DPNr7hRfIi"
   },
   "outputs": [],
   "source": [
    "reloaded_table = rh.table(name=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgwQXHJh7QW3",
    "outputId": "4cd3e578-b72a-4b40-84e2-c5ae34c1e715"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m /Users/caroline/anaconda3/envs/rh-dev/lib/python3.9/site-packages/ray/data/datasource/parquet_datasource.py:233: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m   pq_ds.pieces, **prefetch_remote_args\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m /Users/caroline/anaconda3/envs/rh-dev/lib/python3.9/site-packages/ray/data/datasource/parquet_datasource.py:311: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m   num_files = len(self._pq_ds.pieces)\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m /Users/caroline/anaconda3/envs/rh-dev/lib/python3.9/site-packages/ray/data/datasource/parquet_datasource.py:324: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m   self._pq_ds.pieces[idx]\n",
      "Parquet Files Sample:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "2023-08-29 16:35:50,413\tWARNING read_api.py:330 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id grade\n",
      "0   1     a\n",
      "1   2     b\n",
      "   id grade\n",
      "0   3     b\n",
      "1   4     a\n",
      "   id grade\n",
      "0   5     a\n",
      "1   6     e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caroline/anaconda3/envs/rh-dev/lib/python3.9/site-packages/ray/data/_internal/block_batching.py:399: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "Use get_node_id() instead\n",
      "  node_id = ray.get_runtime_context().node_id\n",
      "Parquet Files Sample: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m /Users/caroline/anaconda3/envs/rh-dev/lib/python3.9/site-packages/ray/data/datasource/parquet_datasource.py:263: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=25611)\u001b[0m   np.array_split(self._pq_ds.pieces, parallelism),\n"
     ]
    }
   ],
   "source": [
    "batches = reloaded_table.stream(batch_size=2)\n",
    "for batch in batches:\n",
    "    print(batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "41BK2zw8yk7H"
   },
   "source": [
    "## Blobs\n",
    "\n",
    "The Runhouse Blob API represents an entity for storing arbitrary data. Blobs are associated with a system (local, remote, or file storage), and can be written down or synced to systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iLAaOVXPbbFY"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "blob_data = list(range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 20:57:10.570715 | Creating new file folder if it does not already exist in path: /Users/caroline/Documents/runhouse/runhouse\n"
     ]
    }
   ],
   "source": [
    "# create and save local blob\n",
    "local_blob = rh.blob(\n",
    "        name=\"local_blob\",\n",
    "        data=blob_data,\n",
    "        system=\"file\",\n",
    "        path=\"local_blob.pickle\"\n",
    "    ).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWz_TF69StEa",
    "outputId": "7cca8d85-0478-4d55-bcda-e3f58e439f9f"
   },
   "outputs": [],
   "source": [
    "# to sync the blob to remote or fs\n",
    "local_blob.to(system=cluster)\n",
    "local_blob.to(system=\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzAEykn7TLGP",
    "outputId": "9c61b1bf-16f1-48a3-978a-7fc8bb43c506"
   },
   "outputs": [],
   "source": [
    "# create blob on s3\n",
    "rh.blob(\n",
    "    data=blob_data,\n",
    "    system=\"s3\",\n",
    "    path=f\"/runhouse-blob/sample_blob.pickle\",\n",
    ")\n",
    "\n",
    "# create blob on cluster\n",
    "rh.blob(\n",
    "    data=blob_data,\n",
    "    system=cluster,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X4DA7y3_76l3"
   },
   "source": [
    "To get the contents from a blob, use `.fetch()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "FltjM0Qm70cz",
    "outputId": "f867a940-7f6c-4691-d3a7-7c1548fe5f45"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(local_blob.fetch())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-UaQpzxo9FA1"
   },
   "source": [
    "Now that you understand the basics, feel free to play around with more complicated scenarios! You can also check out our additional API and example usage tutorials on our [docs site](https://www.run.house/docs)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Rz8GsCvwGnnk"
   },
   "source": [
    "## Cluster Termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "BQjLvOUBWS21",
    "outputId": "049eea20-12ea-4bac-f9be-3c29bb35cf55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Terminating </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">cpu-cluster</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m⠹\u001b[0m \u001b[1;36mTerminating \u001b[0m\u001b[1;32mcpu-cluster\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!sky down cpu-cluster\n",
    "# or\n",
    "cluster.teardown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Ocos3Ko9WB0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
