{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad476255-f312-49ba-8535-85af404f3e76",
   "metadata": {},
   "source": [
    "# Clusters - Advanced\n",
    "\n",
    "This tutorial assumes that you are already familiar with the cluster basics mentioned in [Cluster API tutorial](https://www.run.house/docs/tutorials/api-clusters), which covers Runhouse cluster creation, running a basic function, and some ulitity commands for running on the cluster.\n",
    "\n",
    "This tutorial covers some more advanced features, like setting up Cluster state with a Runhouse Image, using processes on the cluster, and other ways to interact with the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821a876-f91c-4e7b-95f3-79e1a32c3410",
   "metadata": {},
   "source": [
    "## Base Image\n",
    "\n",
    "As you saw in the Cluster API tutorial, Runhouse clusters expose various functions that allow you to set up state, dependencies, and whatnot on all nodes of your cluster, including `install_packages`, `rsync`, `set_env_vars`, and `run_bash`. \n",
    "\n",
    "A Runhouse “Image” is an abstraction that allows you to run these setup steps *before* we install runhouse and bring up the Runhouse daemon and initial set up on your cluster’s nodes. You can also specify a machine or Docker image_id to the Runhouse image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43770fce-c8a2-4d67-b034-bd5ee216deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 12-17 12:04:55 provisioner.py:560] \u001b[32mSuccessfully provisioned cluster: ml_ready_cluster\u001b[0m\n",
      "I 12-17 12:04:57 cloud_vm_ray_backend.py:3402] Run commands not specified or empty.\n",
      "Clusters\n",
      "\u001b[2mAWS: Fetching availability zones mapping...\u001b[0mNAME              LAUNCHED        RESOURCES                                                                  STATUS  AUTOSTOP  COMMAND                       \n",
      "ml_ready_cluster  a few secs ago  1x AWS(m6i.large, image_id={'us-east-1': 'docker:python:3.12.8-bookwor...  UP      (down)    /Users/rohinbhasin/minico...  \n",
      "\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import runhouse as rh\n",
    "\n",
    "image = (\n",
    "    rh.Image(name=\"sample_image\")\n",
    "    .from_docker(\"python:3.12.8-bookworm\")\n",
    "    .install_packages([\"numpy\", \"pandas\"])\n",
    "    .sync_secrets([\"huggingface\"])\n",
    "    .set_env_vars({\"RH_LOG_LEVEL\": \"debug\"})\n",
    ")\n",
    "\n",
    "cluster = rh.cluster(name=\"ml_ready_cluster\", image=image, instance_type=\"CPU:2+\", provider=\"aws\").up_if_not()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d51865c-5377-4f40-9b3c-2f3050f92f7a",
   "metadata": {},
   "source": [
    "The example above will launch a cluster with the base docker image `python:3.12.8-bookworm`, install the given packages, sync over your local huggingface token, and set the Runhouse log level env var, prior to starting the Runhouse Daemon. To continue installing packages, running commands, etc after the Runhouse server is already started, you can directly use the cluster commands.\n",
    "\n",
    "The growing list of setup steps available for runhouse images is available in the [API Reference](https://www.run.house/docs/main/en/api/python/image)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30781474-1fcf-4f8f-bbc9-6a86e8945cfc",
   "metadata": {},
   "source": [
    "## Processes\n",
    "\n",
    "On your Runhouse cluster, whether you have one node or multiple nodes, you may want to run things in different processes on the cluster. \n",
    "\n",
    "There are a few key use cases for separating your logic into different processes:\n",
    "\n",
    "1. Creating processes that require certain amounts of resources.\n",
    "2. Creating processes on specific nodes.\n",
    "3. Creating processes with specific environment variables.\n",
    "4. General OS process isolation -- allowing you to kill things on the cluster without touching other running logic.\n",
    "\n",
    "You can put your Runhouse Functions/Modules into specific processes, or even run bash commands in specific processes.\n",
    "\n",
    "Let's set up a basic cluster and some easy logic to send to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b1583b-6e3b-484a-901f-aa3083831426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_process_attributes():\n",
    "    import os\n",
    "    import time\n",
    "    import socket\n",
    "    \n",
    "    log_level = os.environ.get(\"LOG_LEVEL\")\n",
    "\n",
    "    if log_level == \"DEBUG\":\n",
    "        print(\"Debugging...\")\n",
    "    else:\n",
    "        print(\"No log level set.\")\n",
    "\n",
    "    # Return the IP that this is scheduled on\n",
    "    return socket.gethostbyname(socket.gethostname())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2046e235-7a96-4624-a8c5-b460e0c95733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 12-17 13:12:17 provisioner.py:560] \u001b[32mSuccessfully provisioned cluster: multi-gpu-cluster\u001b[0m\n",
      "I 12-17 13:12:18 cloud_vm_ray_backend.py:3402] Run commands not specified or empty.\n",
      "Clusters\n",
      "\u001b[2mAWS: Fetching availability zones mapping...\u001b[0mNAME               LAUNCHED        RESOURCES                                                                  STATUS  AUTOSTOP  COMMAND                       \n",
      "multi-gpu-cluster  a few secs ago  2x AWS(g5.xlarge, {'A10G': 1})                                             UP      (down)    /Users/rohinbhasin/minico...  \n",
      "ml_ready_cluster   1 hr ago        1x AWS(m6i.large, image_id={'us-east-1': 'docker:python:3.12.8-bookwor...  UP      (down)    /Users/rohinbhasin/minico...  \n",
      "\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import runhouse as rh\n",
    "\n",
    "cluster = rh.cluster(name=\"multi-gpu-cluster\", accelerators=\"A10G:1\", num_nodes=2, provider=\"aws\").up_if_not()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a2728c-dace-4908-a526-2828cef27880",
   "metadata": {},
   "source": [
    "We can now create processes based on whatever requirements we want. Covering all the examples above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63df0a10-e13e-4a3c-8691-c5f9fbe6616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default_process': {'name': 'default_process',\n",
       "  'compute': {},\n",
       "  'runtime_env': None,\n",
       "  'env_vars': {}},\n",
       " 'p1': {'name': 'p1',\n",
       "  'compute': {'GPU': 1},\n",
       "  'runtime_env': {},\n",
       "  'env_vars': None},\n",
       " 'p2': {'name': 'p2',\n",
       "  'compute': {'GPU': 1},\n",
       "  'runtime_env': {},\n",
       "  'env_vars': {'LOG_LEVEL': 'DEBUG'}},\n",
       " 'p3': {'name': 'p3',\n",
       "  'compute': {'node_idx': 1},\n",
       "  'runtime_env': {},\n",
       "  'env_vars': None}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some processes with GPU requirements. These will be on different nodes since each node only has one GPU, and we'll check that\n",
    "p1 = cluster.ensure_process_created(\"p1\", compute={\"GPU\": 1})\n",
    "# This second process will also have an env var set.\n",
    "p2 = cluster.ensure_process_created(\"p2\", compute={\"GPU\": 1}, env_vars={\"LOG_LEVEL\": \"DEBUG\"})\n",
    "\n",
    "# We can also send processes to specific nodes if we want\n",
    "p3 = cluster.ensure_process_created(\"p3\", compute={\"node_idx\": 1})\n",
    "\n",
    "cluster.list_processes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e801e8-a1ca-4a0c-8993-8ff4d217e587",
   "metadata": {},
   "source": [
    "Note that we always create a `default_process`, which is where all Runhouse Functions/Modules end up if you don't specify processes when sending them to the cluster. This `default_process` always lives on the head node of your cluster.\n",
    "\n",
    "Now, let's see where these processes ended up using our utility method set up above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfc8887-9d03-423a-bb1f-2796cb0e82f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-17 13:23:01 | runhouse.resources.functions.function:236 | Because this function is defined in a notebook, writing it out to /Users/rohinbhasin/work/notebooks/see_process_attributes_fn.py to make it importable. Please make sure the function does not rely on any local variables, including imports (which should be moved inside the function body). This restriction does not apply to functions defined in normal Python files.\n",
      "INFO | 2024-12-17 13:23:04 | runhouse.resources.module:507 | Sending module see_process_attributes of type <class 'runhouse.resources.functions.function.Function'> to multi-gpu-cluster\n",
      "INFO | 2024-12-17 13:23:04 | runhouse.servers.http.http_client:439 | Calling see_process_attributes.call\n",
      "\u001b[36mNo log level set.\n",
      "\u001b[0mINFO | 2024-12-17 13:23:04 | runhouse.servers.http.http_client:504 | Time to call see_process_attributes.call: 0.71 seconds\n",
      "172.31.89.87\n"
     ]
    }
   ],
   "source": [
    "remote_f1 = rh.function(see_process_attributes).to(cluster, process=p1)\n",
    "print(remote_f1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbca19b8-e27f-479b-823b-e3f5ec38d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-17 13:23:32 | runhouse.resources.functions.function:236 | Because this function is defined in a notebook, writing it out to /Users/rohinbhasin/work/notebooks/see_process_attributes_fn.py to make it importable. Please make sure the function does not rely on any local variables, including imports (which should be moved inside the function body). This restriction does not apply to functions defined in normal Python files.\n",
      "INFO | 2024-12-17 13:23:34 | runhouse.resources.module:507 | Sending module see_process_attributes of type <class 'runhouse.resources.functions.function.Function'> to multi-gpu-cluster\n",
      "INFO | 2024-12-17 13:23:34 | runhouse.servers.http.http_client:439 | Calling see_process_attributes.call\n",
      "\u001b[36mDebugging...\n",
      "\u001b[0mINFO | 2024-12-17 13:23:35 | runhouse.servers.http.http_client:504 | Time to call see_process_attributes.call: 0.53 seconds\n",
      "172.31.94.40\n"
     ]
    }
   ],
   "source": [
    "remote_f2 = rh.function(see_process_attributes).to(cluster, process=p2)\n",
    "print(remote_f2())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c7a10-8083-486f-ab59-939a647185c7",
   "metadata": {},
   "source": [
    "We can see that, since each process required one GPU, they were scheduled on different machines. You can also see that the environment variable we set in the second process was propagated, as our logging output is different. Let's check now that the 3rd process we explicitly sent to the second node is on the second node.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c15e754-029c-42b4-896d-d415281fad88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-17 13:27:05 | runhouse.resources.functions.function:236 | Because this function is defined in a notebook, writing it out to /Users/rohinbhasin/work/notebooks/see_process_attributes_fn.py to make it importable. Please make sure the function does not rely on any local variables, including imports (which should be moved inside the function body). This restriction does not apply to functions defined in normal Python files.\n",
      "INFO | 2024-12-17 13:27:08 | runhouse.resources.module:507 | Sending module see_process_attributes of type <class 'runhouse.resources.functions.function.Function'> to multi-gpu-cluster\n",
      "INFO | 2024-12-17 13:27:08 | runhouse.servers.http.http_client:439 | Calling see_process_attributes.call\n",
      "\u001b[36mNo log level set.\n",
      "\u001b[0mINFO | 2024-12-17 13:27:08 | runhouse.servers.http.http_client:504 | Time to call see_process_attributes.call: 0.54 seconds\n",
      "172.31.94.40\n"
     ]
    }
   ],
   "source": [
    "remote_f3 = rh.function(see_process_attributes).to(cluster, process=p3)\n",
    "print(remote_f3())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08900e-2e45-4f65-89c6-76e9b0d6dd54",
   "metadata": {},
   "source": [
    "Success! We can also `run_bash` within a specific process, if we want to make sure our bash command runs on the same node as a function we're running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8be2b24e-5f9f-4f2c-81e8-b551b2cb7df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  '1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\\n    inet 127.0.0.1/8 scope host lo\\n       valid_lft forever preferred_lft forever\\n    inet6 ::1/128 scope host \\n       valid_lft forever preferred_lft forever\\n2: ens5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9001 qdisc mq state UP group default qlen 1000\\n    link/ether 12:4c:76:66:e8:bb brd ff:ff:ff:ff:ff:ff\\n    altname enp0s5\\n    inet 172.31.94.40/20 brd 172.31.95.255 scope global dynamic ens5\\n       valid_lft 3500sec preferred_lft 3500sec\\n    inet6 fe80::104c:76ff:fe66:e8bb/64 scope link \\n       valid_lft forever preferred_lft forever\\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \\n    link/ether 02:42:ac:9e:2b:8f brd ff:ff:ff:ff:ff:ff\\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\\n       valid_lft forever preferred_lft forever\\n',\n",
       "  ''],\n",
       " [...]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.run_bash(\"ip addr\", process=p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d01b0c-0181-4c02-9cd0-828e77c98ea4",
   "metadata": {},
   "source": [
    "You can see that this ran on the second node. Finally, you can also kill processes, which you may want to do if you use asyncio to run long running functions in a process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5264231c-ecf1-4dc0-8bd4-64bfb050deb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default_process': {'name': 'default_process',\n",
       "  'compute': {},\n",
       "  'runtime_env': None,\n",
       "  'env_vars': {}},\n",
       " 'p1': {'name': 'p1',\n",
       "  'compute': {'GPU': 1},\n",
       "  'runtime_env': {},\n",
       "  'env_vars': None},\n",
       " 'p2': {'name': 'p2',\n",
       "  'compute': {'GPU': 1},\n",
       "  'runtime_env': {},\n",
       "  'env_vars': {'LOG_LEVEL': 'DEBUG'}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.kill_process(p3)\n",
    "cluster.list_processes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7aa4ee-07d2-4975-8a5d-e79a6077d762",
   "metadata": {},
   "source": [
    "## Interacting with the Cluster\n",
    "\n",
    "Beyond interacting with the cluster through Python APIs, Runhouse also provides other ways of working with the cluster, including easy ways to SSH directly onto the cluster, or creating a notebook tunnel, which will let you locally develop on a notebook that runs on the cluster.\n",
    "\n",
    "To SSH, you can either use the Python API ``cluster.ssh()``, or the CLI command ``runhouse cluster ssh <cluster_name>``\n",
    "\n",
    "To create a notebook, run ``cluster.notebook()``, optionally providing the notebook port. This will tunnel into and launch a notebook from the cluster, and provide a link to use for local development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc2520-4eea-4082-a3e1-2e42835d5b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
