{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7574e9-8ac1-4d85-8280-d7428e18c751",
   "metadata": {},
   "source": [
    "# Docker: Dev and Prod Workflows with Runhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3efa9-8a9e-454f-81a4-2a137eaef820",
   "metadata": {},
   "source": [
    "This guide demonstrates how to use the same Docker image with your Runhouse cluster, for both:\n",
    "\n",
    "* **Production**: running functions and code that is pre-installed on the Docker image\n",
    "* **Local development**: making local edits to your repo, and propagating over those local changes to the cluster for experimentation\n",
    "\n",
    "Afterwards, we provide a script that shows how to easily set up and toggle between these two settings, using the same cluster setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285ab39-8c48-428f-b149-6643af11c0d6",
   "metadata": {},
   "source": [
    "In this example, we are going to be using the [DJLServing 0.27.0 with DeepSpeed 0.12.6](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers) Container, which includes HuggingFace Tranformers (4.39.0), Diffusers (0.16.0), and Accelerate (0.28.0). We will use the container version of these packages to demonstrate the pre-packaged production workflow, as well as local editable versions to showcase the local experimentation use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbe071-b139-40fa-8c17-f40a954441f3",
   "metadata": {},
   "source": [
    "## Docker Cluster Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27acf7-d7c8-47ef-9314-69ba5a6e1f14",
   "metadata": {},
   "source": [
    "Because we are pulling the Docker image from AWS ECR, we need to provide the corresponding credentials in order to properly pull and setup the image on the cluster. This can be done through a Runhouse Docker secret, or by setting environment variables. Please refer to <Guide: Docker Cluster Setup> for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7eadcf-c33e-4bb1-8505-2fb6f5c6560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import runhouse as rh\n",
    "\n",
    "docker_ecr_creds = {\n",
    "    \"username\": \"AWS\",\n",
    "    \"password\": subprocess.run(\"aws ecr get-login-password --region us-west-1\", shell=True, capture_output=True).stdout.strip().decode(\"utf-8\"),\n",
    "    \"server\": \"763104351884.dkr.ecr.us-west-1.amazonaws.com\",\n",
    "}\n",
    "docker_secret = rh.provider_secret(\"docker\", values=docker_ecr_creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d60ca5-c646-4db4-9ece-843ce1960c64",
   "metadata": {},
   "source": [
    "Next, construct a Runhouse image, passing in the docker image ID and secret. Feed this image into the OnDemand cluster factory, and up the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084407c6-3e5b-4267-964b-fd0c61ff1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠴</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Preparing SkyPilot runtime (3/3 - runtime)</span>  \u001b[2mView logs at: ~/sky_logs/sky-2024-12-23-13-56-48-619803/provision.log\u001b[0m\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m⠴\u001b[0m \u001b[1;36mPreparing SkyPilot runtime (3/3 - runtime)\u001b[0m  \u001b[2mView logs at: ~/sky_logs/sky-2024-12-23-13-56-48-619803/provision.log\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32m✓ Cluster launched: diffusers_docker.\u001b[0m  \u001b[2mView logs at: ~/sky_logs/sky-2024-12-23-13-56-48-619803/provision.log\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-23 14:03:39 | runhouse.resources.hardware.launcher_utils:391 | Starting Runhouse server on cluster\n",
      "INFO | 2024-12-23 14:03:39 | runhouse.resources.hardware.cluster:1247 | Restarting Runhouse API server on diffusers_docker.\n",
      "\n",
      "INFO:     Started server process [2929]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:32300 (Press CTRL+C to quit)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<runhouse.resources.hardware.on_demand_cluster.OnDemandCluster at 0x127ea7730>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_image = rh.Image(\"docker_image\").from_docker(\n",
    "    \"djl-inference:0.27.0-deepspeed0.12.6-cu121\", docker_secret=docker_secret\n",
    ")\n",
    "\n",
    "cluster = rh.ondemand_cluster(\n",
    "    name=\"diffusers_docker\",\n",
    "    image=base_image,\n",
    "    instance_type=\"g5.8xlarge\",\n",
    "    provider=\"aws\",\n",
    ")\n",
    "cluster.up_if_not()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370add75-c620-4695-aef6-15b92c3dc7d4",
   "metadata": {},
   "source": [
    "## Sample Function\n",
    "\n",
    "The function we'll be using in our demo is `is_transformers_available` from `diffusers.utils`. We'll first show how to use the base version of this function, which was installed on the box through the cluster setup (e.g. a production setting). Then, we'll show how to propogate up local changes and run them on the cluster, if your local version differs from the one in the Docker container (e.g. different package version, or locally edited)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50383749-9a75-42cb-aec6-7ef0d8fa8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import is_transformers_available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83463857-8f33-4897-8a25-27eff28f59f5",
   "metadata": {},
   "source": [
    "## Production Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26242ae1-bf99-4e03-92a5-f3473c53453c",
   "metadata": {},
   "source": [
    "The core of the production workflow is that the Docker image already contains the exact packages and versions we want, probably published into the registry in CI/CD. We don't want to perform any installs or code changes within the image throughout execution so we can preserve exact reproducibility.\n",
    "\n",
    "**NOTE**: By default, Ray and Runhouse are installed on the ondemand cluster during setup time (generally attempting to match the versions you \n",
    "have locally), unless we detect that they're already present. To make sure that no installs occur in production, please make sure that you have Runhouse and Ray installed in your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b6922-970a-47a6-8293-770e009abaf2",
   "metadata": {},
   "source": [
    "### Defining the Function\n",
    "\n",
    "The function is the `is_transformers_available` function imported above. When creating the function to run remotely on the production Runhouse env, we pass in the flag ``sync_local=False`` to indicate that we want to use the function on the cluster, without re-syncing over anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22912d5c-75d0-4d9f-8e84-4187a3b480b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-23 14:04:57 | runhouse.resources.hardware.ssh_tunnel:91 | Running forwarding command: ssh -T -L 32300:localhost:32300 -i ~/.ssh/sky-key -o Port=10022 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ConnectTimeout=30s -o ForwardAgent=yes -o ProxyCommand='ssh -i ~/.ssh/sky-key -o Port=22 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ConnectTimeout=30s -o ForwardAgent=yes -W %h:%p ubuntu@52.24.239.151' root@localhost\n",
      "INFO | 2024-12-23 14:05:00 | runhouse.resources.module:511 | Sending module is_transformers_available of type <class 'runhouse.resources.functions.function.Function'> to diffusers_docker\n"
     ]
    }
   ],
   "source": [
    "prod_fn = rh.function(is_transformers_available).to(cluster, sync_local=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b104db2-808c-4f00-9d69-9e8b662c9e6c",
   "metadata": {},
   "source": [
    "### Calling the Function\n",
    "\n",
    "Now, simply call the function, and it will detect the corresponding function on the cluster to run. In this case, it returns whether or not transformers is available on the cluster, which it is, as it was part of the Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d60236e-4747-460c-9011-4df55feaa538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-23 14:05:01 | runhouse.servers.http.http_client:439 | Calling is_transformers_available.call\n",
      "INFO | 2024-12-23 14:05:06 | runhouse.servers.http.http_client:504 | Time to call is_transformers_available.call: 4.86 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b44dc-9ed5-4685-a05e-dd58f83794cb",
   "metadata": {},
   "source": [
    "For even more specifics on any setup for running your function, you can also directly use cluster functionality (e.g. setting additional env vars, installing packages/running commands), or construct isolated processes (see Process API guide) with specific compute to run the function on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffb076-dd8e-45ac-8428-1e2818298445",
   "metadata": {},
   "source": [
    "## Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba786982-9d7f-4a2a-8c81-cabc9a9a3d2d",
   "metadata": {},
   "source": [
    "Now for the local development and experimentation case. Let's say we have the HuggingFace ``diffusers`` repository cloned and installed as a local editable package, and are making changes to it that we want reflected when we run it on the cluster. We also have a different version of the transformers package installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8152f-fb8f-4c43-9ad2-c0df8b98c3cf",
   "metadata": {},
   "source": [
    "### Local Changes\n",
    "\n",
    "Let's continue using the `is_transformers_available` function, except this time we'll change the function to return the version number of the transformers package if it exists, instead of ``True``. This shows that we have ``transformers==4.44.2`` installed locally.\n",
    "\n",
    "In my local diffusers/src/diffusers/utils/import_utils.py file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c9811-9d17-4ec1-bf5f-ab658aad7284",
   "metadata": {},
   "source": [
    "```\n",
    "def is_transformers_available():\n",
    "    try:\n",
    "        import transformers\n",
    "        return transformers.__version__\n",
    "    except ImportError:\n",
    "        return False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a8033b-8596-44b2-8070-bbbb7926aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.44.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import is_transformers_available\n",
    "\n",
    "is_transformers_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ad7e1-6df4-4b16-90be-2f14e1175b81",
   "metadata": {},
   "source": [
    "### Installing local version\n",
    "\n",
    "When Runhoue installs packages on the remote cluster, it will check if you have a version of the package locally, as well as whether a version of the package already exists on this cluster. If it already exists remotely, by default the remote package will not be overriden, but you can force the local version by passing in the paramteter ``force_sync_local==True`` to ``cluster.install_packages``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c47d010-8535-4947-a5c3-22bd770928c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.install_packages([\"transformers\", \"diffusers\"], force_sync_local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27651de3-4c49-40f0-8598-504636dac2bd",
   "metadata": {},
   "source": [
    "### Defining the Function\n",
    "\n",
    "Now construct a Runhouse function normally and send it to the cluster. Here, we can leave out the ``sync_local`` flag, which defaults to True - the local function will be synced onto the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8904d0b-4c1c-4fcf-bc9b-37d4c77bd2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-23 14:11:05 | runhouse.resources.module:511 | Sending module is_transformers_available of type <class 'runhouse.resources.functions.function.Function'> to diffusers_docker\n"
     ]
    }
   ],
   "source": [
    "dev_fn = rh.function(is_transformers_available).to(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0708c9-505b-4646-8c7c-bf2cd8f277de",
   "metadata": {},
   "source": [
    "### Calling the Function\n",
    "\n",
    "Now, when we call the function, it returns the version of the transformers library installed, rather than a True/False. It also correctly returns the same version as the locally installed version, showing that both local diffusers and transformers packages were properly synced and installed on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba442ae5-6794-403f-9b04-5a747ed8cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2024-12-23 14:11:19 | runhouse.servers.http.http_client:439 | Calling is_transformers_available.call\n",
      "INFO | 2024-12-23 14:11:21 | runhouse.servers.http.http_client:504 | Time to call is_transformers_available.call: 2.48 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.44.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d28636-c0fa-492f-9e63-36b814b53b3e",
   "metadata": {},
   "source": [
    "## Summary - Setting Up Your Code\n",
    "\n",
    "Here, we implement the above as a script to demonstrate the difference between dev and prod. The script can easily be adapted and shared between teammates developing and working with the same repos, with a flag or variable flip to differentiate between experimentation and production branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276cdf5-6dae-4b00-91c4-cdede1529a64",
   "metadata": {},
   "source": [
    "```\n",
    "from diffusers.utils import is_transformers_available\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cluster = rh.ondemand_cluster(...)\n",
    "    cluster.up_if_not()\n",
    "\n",
    "    if prod:\n",
    "        remote_fn = rh.function(is_transformers_available).to(cluster, sync_local=False)\n",
    "    else:\n",
    "        cluster.install_packages([\"transformers\", \"diffusers\"], )\n",
    "        remote_fn = rh.function(is_transformers_available).to(cluster)\n",
    "\n",
    "    remote_fn()\n",
    "    cluster.teardown()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
