{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7574e9-8ac1-4d85-8280-d7428e18c751",
   "metadata": {},
   "source": [
    "# Docker: Dev and Prod Workflows with Runhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3efa9-8a9e-454f-81a4-2a137eaef820",
   "metadata": {},
   "source": [
    "This guide demonstrates how to use the same Docker image with your Runhouse cluster, for both:\n",
    "\n",
    "* **Production**: running functions and code that is pre-installed on the Docker image\n",
    "* **Local development**: making local edits to your repo, and having local changes propagated over to the cluster for experimentation\n",
    "\n",
    "Afterwards, we provide a script that shows how to easily set up and toggle between these two settings, using the same cluster setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285ab39-8c48-428f-b149-6643af11c0d6",
   "metadata": {},
   "source": [
    "In this example, we are going to be using the [DJLServing 0.27.0 with DeepSpeed 0.12.6](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers) Container, which includes HuggingFace Tranformers (4.39.0), Diffusers (0.16.0), and Accelerate (0.28.0). We will use both the container version of these packages, as well as local editable versions to showcase both production ready and local experimentation use cases for using the same Docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbe071-b139-40fa-8c17-f40a954441f3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27acf7-d7c8-47ef-9314-69ba5a6e1f14",
   "metadata": {},
   "source": [
    "Runhouse uses SkyPilot under the hood to set up the Docker image on the cluster. Because we are pulling the Docker image from AWS ECR, we first set some environment variables necessary to pull the Docker image.\n",
    "\n",
    "For more specific details on getting your Docker image set up with Runhouse, please take a look at <Guide: Docker Cluster Setup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6932689b-1b33-4f1c-bc2b-020a611e3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "! export SKYPILOT_DOCKER_USERNAME=AWS\n",
    "! export SKYPILOT_DOCKER_PASSWORD=$(aws ecr get-login-password --region us-west-1)\n",
    "! export SKYPILOT_DOCKER_SERVER=763104351884.dkr.ecr.us-west-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2996ce1-7bbd-45bd-9a46-97c8045a987e",
   "metadata": {},
   "source": [
    "Once these variables are set, we can import runhouse and construct an ondemand cluster, specifying the container image id as follows, and call `cluster.up_if_not()` to launch the cluster with the Docker image loaded on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8baa1b-cba2-4ffe-99f1-74f5096be651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:18:48.921683 | Loaded Runhouse config from /Users/caroline/.rh/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import runhouse as rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15690898-899a-4a45-a3f2-15b55d5c5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = rh.ondemand_cluster(\n",
    "    name=\"diffusers_docker\",\n",
    "    image_id=\"docker:djl-inference:0.27.0-deepspeed0.12.6-cu121\",\n",
    "    instance_type=\"g5.8xlarge\",\n",
    "    provider=\"aws\",\n",
    ")\n",
    "cluster.up_if_not()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71feb774-341c-43e8-a42b-9639cf2b7ea4",
   "metadata": {},
   "source": [
    "The function we'll be using in our demo is `is_transformers_available` from `diffusers.utils`. We'll first show what using this function directly on the box (e.g. a production setting) looks like. After, we'll show the case if we had local versions of the repositories, that we'd modified, and wanted to test out our changes on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50383749-9a75-42cb-aec6-7ef0d8fa8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import is_transformers_available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83463857-8f33-4897-8a25-27eff28f59f5",
   "metadata": {},
   "source": [
    "## Production Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26242ae1-bf99-4e03-92a5-f3473c53453c",
   "metadata": {},
   "source": [
    "The core of the production workflow is that the Docker image already contains the exact packages and versions we want, probably published into the registry in CI/CD. We don't want to perform any installs or code changes within the image throughout execution so we can preserve exact reproducibility.\n",
    "\n",
    "**NOTE**: By default, Ray and Runhouse are installed on the ondemand cluster during setup time (generally attempting to match the versions you \n",
    "have locally), unless we detect that they're already present. To make sure that no installs occur in production, please make sure that you have Runhouse and Ray installed in your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf20abc-8f87-4839-b9fe-f748b6dc70d2",
   "metadata": {},
   "source": [
    "### Defining the Env\n",
    "\n",
    "Here, we construct a Runhouse env containing anything you need for running your code, that doesn't already live on the cluster. For instance, any environment variables or additional packages that you might need installed. Do **NOT** include the packages already installed on the container that you want pinned to the specific version, in this case diffusers and transformers.\n",
    "\n",
    "Then send and create the env on the cluster by directly calling `env.to(cluster)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401471d7-ebc9-45b8-aa2f-eda4a32a9757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:19:13.168591 | Port 32300 is already in use. Trying next port.\n",
      "INFO | 2024-08-01 02:19:13.172968 | Running forwarding command: ssh -T -L 32301:localhost:32300 -i ~/.ssh/sky-key -o Port=10022 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ConnectTimeout=30s -o ForwardAgent=yes -o ProxyCommand='ssh -T -L 32301:localhost:32300 -i ~/.ssh/sky-key -o Port=22 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ConnectTimeout=30s -o ForwardAgent=yes -W %h:%p ubuntu@3.142.171.243' root@localhost\n",
      "INFO | 2024-08-01 02:19:16.685047 | Calling prod_env._set_env_vars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "\u001b[36mdiffusers_docker\u001b[0m\n",
      "----------------\n",
      "\u001b[36mprod_env env: Calling method _set_env_vars on module prod_env\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:19:17.273890 | Time to call prod_env._set_env_vars: 0.59 seconds\n",
      "INFO | 2024-08-01 02:19:17.350932 | Calling prod_env.install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mprod_env env: Calling method install on module prod_env\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:19:17.929387 | Time to call prod_env.install: 0.58 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<runhouse.resources.envs.env.Env at 0x133a6eb60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_env = rh.env(name=\"prod_env\", env_vars={\"HF_TOKEN\": \"****\"})\n",
    "prod_env.to(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b6922-970a-47a6-8293-770e009abaf2",
   "metadata": {},
   "source": [
    "### Defining the Function\n",
    "\n",
    "The function is the `is_transformers_available` function imported above. When creating the function to run remotely on the production Runhouse env, we pass in the **name** of the Runhouse env. By passing in the env name, rather than the object, it simply signals that we want to use the env that already lives on the cluster, without re-syncing over anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22912d5c-75d0-4d9f-8e84-4187a3b480b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:19:22.140840 | Sending module is_transformers_available of type <class 'runhouse.resources.functions.function.Function'> to diffusers_docker\n"
     ]
    }
   ],
   "source": [
    "prod_fn = rh.function(is_transformers_available).to(cluster, env=prod_env.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b104db2-808c-4f00-9d69-9e8b662c9e6c",
   "metadata": {},
   "source": [
    "### Calling the Function\n",
    "\n",
    "Now, simply call the function, and it will detect the corresponding function on the cluster to run. In this case, it returns whether or not transformers is available on the cluster, which it is, as it was part of the Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d60236e-4747-460c-9011-4df55feaa538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:19:27.817880 | Calling is_transformers_available.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mprod_env env: Calling method call on module is_transformers_available\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:19:31.554237 | Time to call is_transformers_available.call: 3.74 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffb076-dd8e-45ac-8428-1e2818298445",
   "metadata": {},
   "source": [
    "## Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba786982-9d7f-4a2a-8c81-cabc9a9a3d2d",
   "metadata": {},
   "source": [
    "Now for the local development and experimentation case. Let's say we have the HuggingFace diffusers and transformers repositories cloned and installed as a local editable package, and are making changes to it that we want reflected when we run it on the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8152f-fb8f-4c43-9ad2-c0df8b98c3cf",
   "metadata": {},
   "source": [
    "### Local Changes\n",
    "\n",
    "Let's continue using the `is_transformers_available` function, except this time we'll change the function to return the version number of the transformers package if it exists, instead of True.\n",
    "\n",
    "In my local diffusers/src/diffusers/utils/import_utils.py file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c9811-9d17-4ec1-bf5f-ab658aad7284",
   "metadata": {},
   "source": [
    "```\n",
    "def is_transformers_available:\n",
    "    try:\n",
    "        import transformers\n",
    "        return transformers.__version__\n",
    "    except ImportError:\n",
    "        return False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a8033b-8596-44b2-8070-bbbb7926aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.44.0.dev0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import is_transformers_available\n",
    "\n",
    "is_transformers_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ed378-725d-4db9-aad2-e78052db4f04",
   "metadata": {},
   "source": [
    "### Defining the Env\n",
    "\n",
    "In this case, because we want to use our local diffusers package, as well as our local transformers package and version, we include these as requirements inside our Runhouse env. There is no need to preemptively send over the env, as now we can directly pass in the env object when we define the function, to sync over the local changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04364959-23a7-4030-8b7c-351779c5eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_env = rh.env(name=\"dev_env\", env_vars={\"HF_TOKEN\": \"****\"}, reqs=[\"diffusers\", \"transformers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27651de3-4c49-40f0-8598-504636dac2bd",
   "metadata": {},
   "source": [
    "### Defining the Function\n",
    "\n",
    "Define a Runhouse function normally, passing in the function, and sending it to the cluster. Here, we simply pass in the `dev_env` object into the env argument. This will ensure that the folder that this function is locally found in, along with any requirements in the env requirements is synced over to the cluster properly. Even though the container already contains its own version of these packages, requirements that can be found locally, such as our local modified diffusers and transformers (v 4.44.0.dev0) repositories will be synced to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8904d0b-4c1c-4fcf-bc9b-37d4c77bd2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:34:20.997084 | Copying package from file:///Users/caroline/Documents/diffusers to: diffusers_docker\n",
      "INFO | 2024-08-01 02:34:24.924803 | Copying package from file:///Users/caroline/Documents/transformers to: diffusers_docker\n",
      "INFO | 2024-08-01 02:34:31.626250 | Calling dev_env._set_env_vars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mdev_env env: Calling method _set_env_vars on module dev_env\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:34:32.324740 | Time to call dev_env._set_env_vars: 0.7 seconds\n",
      "INFO | 2024-08-01 02:34:32.444053 | Calling dev_env.install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mdev_env env: Calling method install on module dev_env\n",
      "\u001b[0m\u001b[36mInstalling Package: diffusers with method pip.\n",
      "\u001b[0m\u001b[36mRunning via install_method pip: python3 -m pip install /root/diffusers\n",
      "\u001b[0m\u001b[36mInstalling Package: transformers with method pip.\n",
      "\u001b[0m\u001b[36mRunning via install_method pip: python3 -m pip install /root/transformers\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:34:56.084695 | Time to call dev_env.install: 23.64 seconds\n",
      "INFO | 2024-08-01 02:34:56.239915 | Sending module is_transformers_available of type <class 'runhouse.resources.functions.function.Function'> to diffusers_docker\n"
     ]
    }
   ],
   "source": [
    "dev_fn = rh.function(is_transformers_available).to(cluster, env=dev_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0708c9-505b-4646-8c7c-bf2cd8f277de",
   "metadata": {},
   "source": [
    "### Calling the Function\n",
    "\n",
    "Now, we call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba442ae5-6794-403f-9b04-5a747ed8cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:35:01.303550 | Calling is_transformers_available.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mdev_env env: Calling method call on module is_transformers_available\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-08-01 02:35:02.946712 | Time to call is_transformers_available.call: 1.64 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.44.0.dev0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d28636-c0fa-492f-9e63-36b814b53b3e",
   "metadata": {},
   "source": [
    "## Summary - Setting Up Your Code\n",
    "\n",
    "Here, we implement the above as a script that can be used to toggle between dev and prod. The script can easily be adapted and shared between teammates developing and working with the same repos, with a flag or variable flip to differentiate between experimentation and production branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276cdf5-6dae-4b00-91c4-cdede1529a64",
   "metadata": {},
   "source": [
    "```\n",
    "from diffusers.utils import is_transformers_available\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cluster = rh.ondemand_cluster(...)\n",
    "    cluster.up_if_not()\n",
    "\n",
    "    if prod:\n",
    "        env = rh.env(name=\"prod_env_name\", env_vars={...}, ...)\n",
    "        env.to(cluster)\n",
    "        remote_fn = rh.function(is_transformers_available).to(cluster, env=env.name)\n",
    "    else:\n",
    "        env = rh.env(name=\"dev_env_name\", reqs=[\"diffusers\", \"trasnformers\"], ...)\n",
    "        remote_fn = rh.function(is_transformers_available).to(cluster, env=env)\n",
    "\n",
    "    remote_fn()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd83df-e684-4e52-9aab-484f31e26dea",
   "metadata": {},
   "source": [
    "To summarize the core differences between local experimentation and production workflow:\n",
    "\n",
    "**Local Development**: Include local packages to sync in the `reqs` field of the `env` that the function is associated with.\n",
    "\n",
    "**Production Workflow**: Do not include production packages that are part of the Docker image in the `reqs` field of the `env`. Send the `env` to the cluster prior to defining the function, and then pass in the env name rather than the env object for the function. Also, include Runhouse and Ray on the image to pin those for production as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
